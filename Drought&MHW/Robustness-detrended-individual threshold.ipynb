{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate robusteness from pi control runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some definitions\n",
    "\n",
    "# directory of data\n",
    "#fdir = '~/Google Drive/professional/research/FARALLON_INSTITUTE_PROJECTS/2020 NOAA MAPP/Climate_extremes_sharedfigsandcode/data/FOR SCATTER PLOT/'\n",
    "fdir = '/Volumes/GoogleDrive/My Drive/Climate_extremes_sharedfigsandcode/data/FOR SCATTER PLOT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore') #filter some warning messages\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_coevents(y1, y2, pct1, pct2, runs='picontrol'):\n",
    "    # \n",
    "    fin1 = fdir+'anomaly ts/'+runs+'_goa_sst_anom.nc'\n",
    "    fin2 = fdir+'anomaly ts/'+runs+'_sm_anom.nc'\n",
    "    modsst = xr.open_dataset(fin1)\n",
    "    modsst.close()\n",
    "    modsm2 = xr.open_dataset(fin2)\n",
    "    modsm2.close()\n",
    "    \n",
    "    models = modsm2.model\n",
    "\n",
    "    # selec periood\n",
    "    modsst = modsst.sel(year=slice(y1,y2))\n",
    "    modsm2 = modsm2.sel(year=slice(y1,y2))\n",
    "    \n",
    "    nev = list()\n",
    "    \n",
    "    for ix,i in enumerate(models):\n",
    "        #print(ix,i)\n",
    "        tmp1= modsst.sel(model=i).sst.values\n",
    "        tmp2= modsm2.sel(model=i).sm.values\n",
    "    \n",
    "        # calculate threshold\n",
    "        mhw_thr = np.nanpercentile(tmp1,pct1)\n",
    "        drg_thr = np.nanpercentile(tmp2,pct2)\n",
    "    \n",
    "        a1 = tmp1>=mhw_thr\n",
    "        a2 = tmp2<=drg_thr\n",
    "        \n",
    "        tmp = np.full((len(modsst.year.values),1),1)\n",
    "        tmp = tmp[a1*a2]\n",
    "    \n",
    "        nev.append(len(tmp))#/(y2-y1+1)) #freq.\n",
    "        \n",
    "    return nev  # sum(nev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 2, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1],\n",
       " [0, 2, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 2, 0, 0, 0, 2, 0],\n",
       " [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 2, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 2, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny = 30\n",
    "prc1 = 90\n",
    "prc2 = 10\n",
    "\n",
    "pinev=list()\n",
    "for i in range(int(500/ny)):\n",
    "    nev = num_coevents(i*ny, (i+1)*ny-1, prc1, prc2)\n",
    "    pinev.append(nev)\n",
    "pinev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25  , 0.4375, 0.25  , 0.4375, 0.1875, 0.4375, 0.125 , 0.125 ,\n",
       "       0.3125, 0.125 , 0.4375, 0.5625, 0.375 , 0.4375, 0.1875, 0.5625,\n",
       "       0.375 , 0.25  , 0.375 , 0.4375, 0.1875, 0.25  ])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mean=np.mean(pinev,axis=0)\n",
    "model_spread=np.std(pinev,axis=0)\n",
    "model_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16 30-yr periods MMEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.5       , 0.27272727, 0.36363636, 0.22727273, 0.5       ,\n",
       "        0.40909091, 0.18181818, 0.36363636, 0.22727273, 0.22727273,\n",
       "        0.18181818, 0.31818182, 0.40909091, 0.36363636, 0.27272727,\n",
       "        0.36363636]),\n",
       " 0.5500570308051732)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mme_mean=np.mean(pinev,axis=1)\n",
    "mme_spread=np.std(pinev,axis=1)\n",
    "#internal variability mean and spread\n",
    "mme_mean,np.mean(mme_spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MME mean and spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.32386363636363635, 0.09890281355414325)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mme_model_mean=np.mean(mme_mean)\n",
    "mme_model_spread=np.std(mme_mean)\n",
    "mme_model_mean,mme_model_spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross model mean and spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.32386363636363635, 0.134095724104613)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_model_mean=np.mean(model_mean)\n",
    "cross_model_spread=np.std(model_mean)\n",
    "cross_model_mean,cross_model_spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate thresholds for PI Control runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thre(fdir, runs, y1,y2,prc1,prc2):\n",
    "    # open data: anomalies (without trend)\n",
    "\n",
    "    modsst = xr.open_dataset(fdir+'anomaly ts/'+runs+'_goa_sst_anom.nc')\n",
    "    modsst.close()\n",
    "    modsm2 = xr.open_dataset(fdir+'anomaly ts/'+runs+'_sm_anom.nc')\n",
    "    modsm2.close()\n",
    "\n",
    "    # select period \n",
    "    modsst = modsst.sel(year=slice(y1,y2))\n",
    "    modsm2 = modsm2.sel(year=slice(y1,y2))\n",
    "    mhw_thr = list()\n",
    "    drg_thr = list()\n",
    "    models = list()\n",
    "\n",
    "    # Calculate thresholds for each model\n",
    "    for ix,i in enumerate(modsm2.model.values):\n",
    "        tmp1= modsst.sel(model=i).sst.values\n",
    "        tmp2= modsm2.sel(model=i).sm.values\n",
    "        \n",
    "        mhw_thr.append(np.nanpercentile(tmp1,prc1))\n",
    "        drg_thr.append(np.nanpercentile(tmp2,prc2))\n",
    "\n",
    "        models.append(i)\n",
    "    \n",
    "    return mhw_thr, drg_thr, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of events for control, historical and future\n",
    "# based on thresholds in each run\n",
    "\n",
    "def freq_coevents(fdir, runs, mhw_thr, drg_thr, models, y1, y2):\n",
    "    #pi control\n",
    "    fi1 = fdir+'anomaly ts/'+runs+'_goa_sst_anom.nc'\n",
    "    fi2 = fdir+'anomaly ts/'+runs+'_sm_anom.nc'\n",
    "    modsst = xr.open_dataset(fi1)\n",
    "    modsst.close()\n",
    "    modsm2 = xr.open_dataset(fi2)\n",
    "    modsm2.close()\n",
    "\n",
    "    # select period\n",
    "    modsst = modsst.sel(year=slice(y1,y2))\n",
    "    modsm2 = modsm2.sel(year=slice(y1,y2))\n",
    "\n",
    "    nev = list()\n",
    "\n",
    "    for ix,i in enumerate(models):\n",
    "        #print(ix,i)\n",
    "        tmp1= modsst.sel(model=i).sst.values\n",
    "        tmp2= modsm2.sel(model=i).sm.values\n",
    "\n",
    "        a1 = tmp1>=mhw_thr[ix]\n",
    "        a2 = tmp2<=drg_thr[ix]\n",
    "        tmp = np.full((len(modsst.year.values),1),1)\n",
    "        tmp = tmp[a1*a2]\n",
    "\n",
    "        nev.append(len(tmp))\n",
    "    \n",
    "    freq = np.array(nev)/(y2-y1+1)\n",
    "    \n",
    "    return nev,np.round(np.nanmean(nev),4), np.round(np.nanstd(nev),4) #mean no. of events\n",
    "#freq, np.round(np.nanmean(freq),4), np.round(np.nanstd(freq),4) #mean frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_difruns(fdir,ny, prc1, prc2):\n",
    "    \n",
    "    # calculate threshold in pi control\n",
    "    y2=2014\n",
    "    y1=y2-ny+1\n",
    "    mhw_thr, drg_thr, models = get_thre(fdir, 'picontrol',y1,y2,prc1,prc2)\n",
    "\n",
    "    print ('Percentiles: '+str(prc1)+'/'+str(prc2))\n",
    "    # pi control\n",
    "    print('piControl')\n",
    "    y2=2014\n",
    "    y1=y2-ny+1\n",
    "    freq, mfrq, sfrq = freq_coevents(fdir,'picontrol',mhw_thr,drg_thr, models,y1,y2)\n",
    "    print(mfrq,sfrq)\n",
    "    \n",
    "    # calculate threshold in historical 1\n",
    "    y1 = 1900\n",
    "    y2 = y1+ny-1\n",
    "    mhw_thr, drg_thr, models = get_thre(fdir, 'historical',y1,y2,prc1,prc2)\n",
    "\n",
    "    # historical 1\n",
    "    y1 = 1900\n",
    "    y2 = y1+ny-1\n",
    "    print('\\nhistorical: '+str(y1)+'-'+str(y2))\n",
    "    freq, mfrq, sfrq = freq_coevents(fdir,'historical',mhw_thr,drg_thr, models, y1,y2)\n",
    "    print(mfrq,sfrq)\n",
    "\n",
    "       \n",
    "    # calculate threshold in historical 2\n",
    "    y2=2014\n",
    "    y1=y2-ny+1\n",
    "    mhw_thr, drg_thr, models = get_thre(fdir, 'historical',y1,y2,prc1,prc2)\n",
    "\n",
    "    # historical 2\n",
    "    y2=2014\n",
    "    y1=y2-ny+1\n",
    "    print('\\nhistorical 2: '+str(y1)+'-'+str(y2))\n",
    "    freq1, mfrq, sfrq = freq_coevents(fdir,'historical',mhw_thr,drg_thr, models, y1,y2)\n",
    "    print(mfrq,sfrq)\n",
    "    \n",
    "    # calculate threshold in historical 2\n",
    "    y2=2099\n",
    "    y1=y2-ny+1\n",
    "    mhw_thr, drg_thr, models = get_thre(fdir, 'ssp585',y1,y2,prc1,prc2)\n",
    "\n",
    "    # future\n",
    "    y2=2099\n",
    "    y1=y2-ny+1\n",
    "    print('\\nfuture: '+str(y1)+'-'+str(y2))\n",
    "    freq2, mfrq, sfrq = freq_coevents(fdir,'ssp585',mhw_thr,drg_thr, models, y1,y2)\n",
    "    print(mfrq,sfrq)\n",
    "    return freq1, freq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of events - detrended data, using individual threshols\n",
    "## percentiles 90-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentiles: 90/10\n",
      "\n",
      "Probable # events in 30 years: 0.3\n",
      "Percentiles: 90/10\n",
      "piControl\n",
      "0.0 0.0\n",
      "\n",
      "historical: 1900-1929\n",
      "0.5455 0.6556\n",
      "\n",
      "historical 2: 1985-2014\n",
      "0.2727 0.5378\n",
      "\n",
      "future: 2070-2099\n",
      "0.6364 0.5677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 2, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print ('\\nPercentiles: '+str(prc1)+'/'+str(prc2))\n",
    "print('\\nProbable # events in '+str(ny)+' years'+': '+str(ny*0.01))\n",
    "\n",
    "hinev,funev=freq_difruns(fdir,ny, prc1, prc2)\n",
    "funev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16 MMEs diff and spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3125, 0.09890281355414324)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff=np.mean(funev)-mme_mean\n",
    "diff_mean=np.mean(diff)\n",
    "diff_spread=np.std(diff)\n",
    "diff_mean,diff_spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model by model diff and spread, not right in this case as future only has 1 period, large spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.75,\n",
       " -0.4375,\n",
       " 0.75,\n",
       " -0.4375,\n",
       " -0.1875,\n",
       " 0.5625,\n",
       " 0.875,\n",
       " -0.125,\n",
       " -0.3125,\n",
       " 0.875,\n",
       " 0.5625,\n",
       " 1.4375,\n",
       " -0.375,\n",
       " 0.5625,\n",
       " -0.1875,\n",
       " 0.4375,\n",
       " -0.375,\n",
       " -0.25,\n",
       " 0.625,\n",
       " 0.5625,\n",
       " 0.8125,\n",
       " 0.75]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff=list()\n",
    "zip_obj=zip(funev,model_mean)\n",
    "for i , j in zip_obj:\n",
    "        diff.append(i-j)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3125, 0.5458391163237487)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_mean=np.mean(diff)\n",
    "diff_spread=np.std(diff)\n",
    "diff_mean,diff_spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
