{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-ocurrence of Extreme Drought and Marine Heat Waves in the California Current\n",
    "\n",
    "# <font color=blue>Hypothesis:</font>\n",
    "## <font color=blue>Will extreme droughts and marine heat waves occur simultaneously more often because of anthropogenic climate change? </font>\n",
    "\n",
    "### We will test this hypothesis by comparinig the number of co-ocurring events in CMIP6 climate models for control, historical and future runs.\n",
    "\n",
    "### We define extreme droughts as  years below the 10% long-term average of California 2m soil moisture July-June mean values\n",
    "\n",
    "### We define marine heatwaves as years above the 90% long-term average of California Current Sea Surface Temperature July-June mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some definitions\n",
    "\n",
    "# directory of data\n",
    "fdir = '~/Google Drive/professional/research/FARALLON_INSTITUTE_PROJECTS/2020 NOAA MAPP/Climate_extremes_sharedfigsandcode/data/FOR SCATTER PLOT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore') #filter some warning messages\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# personal functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate thresholds for PI Control runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of events for control, historical and future\n",
    "# based on pi control thresholds\n",
    "\n",
    "def freq_coevents(fdir, runs, mhw_thr, drg_thr, y1, y2):\n",
    "    #pi control\n",
    "    fi1 = fdir+'anomaly ts/'+runs+'_sst_anom.nc'\n",
    "    fi2 = fdir+'anomaly ts/'+runs+'_sm_anom.nc'\n",
    "    modsst = xr.open_dataset(fi1)\n",
    "    modsst.close()\n",
    "    modsm2 = xr.open_dataset(fi2)\n",
    "    modsm2.close()\n",
    "\n",
    "    # select period\n",
    "    modsst = modsst.sel(year=slice(y1,y2))\n",
    "    modsm2 = modsm2.sel(year=slice(y1,y2))\n",
    "\n",
    "    nev = list()\n",
    "\n",
    "    for ix,i in enumerate(models):\n",
    "        #print(ix,i)\n",
    "        tmp1= modsst.sel(model=i).sst.values\n",
    "        tmp2= modsm2.sel(model=i).sm.values\n",
    "\n",
    "        a1 = tmp1>=mhw_thr[ix]\n",
    "        a2 = tmp2<=drg_thr[ix]\n",
    "        tmp = np.full((len(modsst.year.values),1),1)\n",
    "        tmp = tmp[a1*a2]\n",
    "\n",
    "        nev.append(len(tmp))\n",
    "    \n",
    "    freq = np.array(nev)/(y2-y1+1)\n",
    "    \n",
    "    return freq, np.round(np.nanmean(freq),4), np.round(np.nanstd(freq),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thre(y1,y2,prc1,prc2):\n",
    "    # open data: anomalies (without trend)\n",
    "\n",
    "    modsst = xr.open_dataset(fdir+'anomaly ts/picontrol_sst_anom.nc')\n",
    "    modsst.close()\n",
    "    modsm2 = xr.open_dataset(fdir+'anomaly ts/picontrol_sm_anom.nc')\n",
    "    modsm2.close()\n",
    "\n",
    "    # select period \n",
    "    modsst = modsst.sel(year=slice(y1,y2))\n",
    "    modsm2 = modsm2.sel(year=slice(y1,y2))\n",
    "    mhw_thr = list()\n",
    "    drg_thr = list()\n",
    "    models = list()\n",
    "\n",
    "    # Calculate thresholds for each model\n",
    "    for ix,i in enumerate(modsm2.model.values):\n",
    "        tmp1= modsst.sel(model=i).sst.values\n",
    "        tmp2= modsm2.sel(model=i).sm.values\n",
    "        \n",
    "        mhw_thr.append(np.percentile(tmp1,prc1))\n",
    "        drg_thr.append(np.percentile(tmp2,prc2))\n",
    "\n",
    "        models.append(i)\n",
    "    \n",
    "    return mhw_thr, drg_thr, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_difruns(ny, prc1, prc2):\n",
    "    \n",
    "    # calculate threshold in pi control\n",
    "    y2=2014\n",
    "    y1=y2-ny+1\n",
    "    mhw_thr, drg_thr, models = get_thre(y1,y2,prc1,prc2)\n",
    "\n",
    "    print ('Percentiles: '+str(prc1)+'/'+str(prc2))\n",
    "    # pi control\n",
    "    print('piControl')\n",
    "    y2=2014\n",
    "    y1=y2-ny+1\n",
    "    freq, mfrq, sfrq = freq_coevents(fdir,'picontrol',mhw_thr,drg_thr, y1,y2)\n",
    "    print(mfrq,sfrq)\n",
    "\n",
    "    # historical 1\n",
    "    y1 = 1900\n",
    "    y2 = y1+ny-1\n",
    "    print('\\nhistorical: '+str(y1)+'-'+str(y2))\n",
    "    freq, mfrq, sfrq = freq_coevents(fdir,'historical',mhw_thr,drg_thr, y1,y2)\n",
    "    print(mfrq,sfrq)\n",
    "\n",
    "    # historical 2\n",
    "    y2=2014\n",
    "    y1=y2-ny+1\n",
    "    print('\\nhistorical 2: '+str(y1)+'-'+str(y2))\n",
    "    freq, mfrq, sfrq = freq_coevents(fdir,'historical',mhw_thr,drg_thr, y1,y2)\n",
    "    print(mfrq,sfrq)\n",
    "\n",
    "    # future\n",
    "    y2=2099\n",
    "    y1=y2-ny+1\n",
    "    print('\\nfuture: '+str(y1)+'-'+str(y2))\n",
    "    freq, mfrq, sfrq = freq_coevents(fdir,'ssp585',mhw_thr,drg_thr, y1,y2)\n",
    "    print(mfrq,sfrq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency of events - detrended data, using pi control threshols\n",
    "## percentiles 80-20\n",
    "## Probability 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles: 80/20\n",
      "piControl\n",
      "0.0273 0.0259\n",
      "\n",
      "historical: 1900-1929\n",
      "0.0318 0.0275\n",
      "\n",
      "historical 2: 1985-2014\n",
      "0.0364 0.0361\n",
      "\n",
      "future: 2070-2099\n",
      "0.0364 0.03\n"
     ]
    }
   ],
   "source": [
    "freq_difruns(30, 80, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency of events - detrended data, using pi control threshols\n",
    "## percentiles 90-10\n",
    "## Probability 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles: 90/10\n",
      "piControl\n",
      "0.0061 0.0129\n",
      "\n",
      "historical: 1900-1929\n",
      "0.0091 0.0179\n",
      "\n",
      "historical 2: 1985-2014\n",
      "0.0106 0.021\n",
      "\n",
      "future: 2070-2099\n",
      "0.0106 0.0233\n"
     ]
    }
   ],
   "source": [
    "freq_difruns(30, 90, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
